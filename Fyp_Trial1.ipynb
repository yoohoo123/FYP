{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all python package needed for importing data\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit,train_test_split,GridSearchCV\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pymongo and pandas to connect mongodb to juypter and pandas to convert into df/dt\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "def _connect_mongo(host, port, username, password, database_name):\n",
    "    \"\"\" A util for making a connection to mongo \"\"\"\n",
    "\n",
    "    if username and password:\n",
    "        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, database_name)\n",
    "        conn = MongoClient(mongo_uri)\n",
    "    else:\n",
    "        conn = MongoClient(host, port)\n",
    "\n",
    "\n",
    "    return conn[database_name]\n",
    "\n",
    "\n",
    "def read_mongo(database_name, collection_name, query, host, port, username, password, no_id = True):\n",
    "    \"\"\" Read from Mongo and Store into DataFrame \"\"\"\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    database_name = _connect_mongo(host=host, port=port, username=username, password=password, database_name=database_name)\n",
    "\n",
    "    # Make a query to the specific DB and Collection\n",
    "    cursor = database_name[collection_name].find(query)\n",
    "\n",
    "    # Expand the cursor and construct the DataFrame\n",
    "    df =  pd.DataFrame(iter(cursor))\n",
    "\n",
    "    # Delete the _id\n",
    "    if '_id' in df.columns:\n",
    "        del df['_id']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['show_id', 'type', 'title', 'cast', 'country', 'date_added',\n",
       "       'release_year', 'rating', 'duration', 'listed_in', 'description',\n",
       "       'director'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#declare database from mongodb\n",
    "\n",
    "#Change depending on user parameters\n",
    "host = \"localhost\"\n",
    "port = 27017\n",
    "username=None\n",
    "password=None\n",
    "query = {}\n",
    "mongo_uri = \"mongodb://localhost:27017\"\n",
    "database_name = \"Fyp-Test\"\n",
    "collection_name = \"Netflix_Titles\"\n",
    "\n",
    "#Read file from database\n",
    "df = read_mongo(database_name,collection_name,query,host,port,username,password)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'type', 'listed_in'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre-propessing data \n",
    "#We want to find out what the relation between Rating ,duration and genre to see if there any correlation\n",
    "\n",
    "\n",
    "#Remove columns except rating, type and genre\n",
    "df = df[['rating','type','listed_in']]\n",
    "\n",
    "#Check for any null values, if there is remove it\n",
    "df['rating'].isnull().sum().sum()\n",
    "df['type'].isnull().sum().sum()\n",
    "df['listed_in'].isnull().sum().sum()\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'listed_in', 'rating_NC-17', 'rating_NR', 'rating_PG',\n",
       "       'rating_PG-13', 'rating_R', 'rating_TV-14', 'rating_TV-G',\n",
       "       'rating_TV-MA', 'rating_TV-PG', 'rating_TV-Y', 'rating_TV-Y7',\n",
       "       'rating_TV-Y7-FV', 'rating_UR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use get_dummies to sort the ratings\n",
    "df = pd.get_dummies(df,prefix=['rating'], columns = ['rating'], drop_first=True)\n",
    "df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separted the type into movies and tv show using bins\n",
    "#create a function to split movies to 1 and TV shows to 2\n",
    "def fun(types):\n",
    "    if types == 'Movie':\n",
    "        return '1'\n",
    "    elif types =='TV Show':\n",
    "        return '2'\n",
    "\n",
    "#pass function to df\n",
    "df['type'] = df['type'].apply(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split listed_in into different cat\n",
    "from pandas import Series\n",
    "\n",
    "\n",
    "temp_df = df['listed_in'].str.split(', ').apply(Series,1).stack()\n",
    "\n",
    "#lined up with df index\n",
    "temp_df.index = temp_df.index.droplevel(-1)\n",
    "#name the column to join\n",
    "temp_df.name = 'listed_in'\n",
    "#del current listed_in\n",
    "del df['listed_in']\n",
    "#join the new listed_in\n",
    "df = df.join(temp_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'rating_NC-17', 'rating_NR', 'rating_PG', 'rating_PG-13',\n",
       "       'rating_R', 'rating_TV-14', 'rating_TV-G', 'rating_TV-MA',\n",
       "       'rating_TV-PG', 'rating_TV-Y', 'rating_TV-Y7', 'rating_TV-Y7-FV',\n",
       "       'rating_UR', 'listed_in_Anime Features', 'listed_in_Anime Series',\n",
       "       'listed_in_British TV Shows', 'listed_in_Children & Family Movies',\n",
       "       'listed_in_Classic & Cult TV', 'listed_in_Classic Movies',\n",
       "       'listed_in_Comedies', 'listed_in_Crime TV Shows',\n",
       "       'listed_in_Cult Movies', 'listed_in_Documentaries',\n",
       "       'listed_in_Docuseries', 'listed_in_Dramas',\n",
       "       'listed_in_Faith & Spirituality', 'listed_in_Horror Movies',\n",
       "       'listed_in_Independent Movies', 'listed_in_International Movies',\n",
       "       'listed_in_International TV Shows', 'listed_in_Kids' TV',\n",
       "       'listed_in_Korean TV Shows', 'listed_in_LGBTQ Movies',\n",
       "       'listed_in_Movies', 'listed_in_Music & Musicals',\n",
       "       'listed_in_Reality TV', 'listed_in_Romantic Movies',\n",
       "       'listed_in_Romantic TV Shows', 'listed_in_Sci-Fi & Fantasy',\n",
       "       'listed_in_Science & Nature TV', 'listed_in_Spanish-Language TV Shows',\n",
       "       'listed_in_Sports Movies', 'listed_in_Stand-Up Comedy',\n",
       "       'listed_in_Stand-Up Comedy & Talk Shows',\n",
       "       'listed_in_TV Action & Adventure', 'listed_in_TV Comedies',\n",
       "       'listed_in_TV Dramas', 'listed_in_TV Horror', 'listed_in_TV Mysteries',\n",
       "       'listed_in_TV Sci-Fi & Fantasy', 'listed_in_TV Shows',\n",
       "       'listed_in_TV Thrillers', 'listed_in_Teen TV Shows',\n",
       "       'listed_in_Thrillers'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#onehot the listen_in\n",
    "df = pd.get_dummies(df,prefix=['listed_in'], columns = ['listed_in'], drop_first=True)\n",
    "df.columns\n",
    "#Data preprocessing is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to split the data into x_train, y_train , x_test , y_test\n",
    "#For this case we will be using train_test_split , in the future we will be using the others\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,train_test_split,GridSearchCV\n",
    "\n",
    "#declare x and y to be df and df['type']\n",
    "#We will split into 20/80\n",
    "x = df.iloc[:,df.columns !='type']\n",
    "y = df['type']\n",
    "\n",
    "x_train , x_test ,y_train , y_test = train_test_split(x,y, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once we have split the data we can choose a classification model since we want to find out if type and listed_in affects the rating\n",
    "#Since the outcome will either be 1 or 0 depending if the ratings is yes or no , we have 5 options : \n",
    "# Naive Bayes\n",
    "# k-Nearest Neighbors\n",
    "# Decision Trees\n",
    "# Support Vector Machine\n",
    "# Logistic Regression\n",
    "#we will start with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "# first we must import gaussiannb(The basic Naive bayes)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#we will set a var to Gaussian\n",
    "Gaussian = GaussianNB()\n",
    "\n",
    "#First we will test with our train data first without changing the parameters - Pre tuning\n",
    "pre_tune_NB_fit = Gaussian.fit(x_train, y_train)\n",
    "pre_tune_NB_predict = pre_tune_NB_fit.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2244   81]\n",
      " [   0 1090]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.97      0.98      2325\n",
      "           2       0.93      1.00      0.96      1090\n",
      "\n",
      "    accuracy                           0.98      3415\n",
      "   macro avg       0.97      0.98      0.97      3415\n",
      "weighted avg       0.98      0.98      0.98      3415\n",
      "\n",
      "0.976281112737921\n"
     ]
    }
   ],
   "source": [
    "#import using sklearn to present the predicted data\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Shows the accuracy/information of the predict\n",
    "print(confusion_matrix(y_test, pre_tune_NB_predict))\n",
    "print(classification_report(y_test, pre_tune_NB_predict))\n",
    "print(accuracy_score(y_test, pre_tune_NB_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post tune\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#Set the numbers of folds and cross validation\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=5, \n",
    "                                    n_repeats=3, \n",
    "                                    random_state=999)\n",
    "\n",
    "import numpy as np\n",
    "np.logspace(0,-9, num=10)\n",
    "\n",
    "np.random.seed(999)\n",
    "\n",
    "#Change Portion of the largest variance of all features that is added to variances for calculation stability.\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "gs_NB = GridSearchCV(estimator=Gaussian, \n",
    "                     param_grid=params_NB, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1,\n",
    "                     scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "post_tune_NB_fit = gs_NB.fit(x_train,y_train)\n",
    "\n",
    "#Predict after post tune\n",
    "post_tune_NB_predict =post_tune_NB_fit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2317    8]\n",
      " [   0 1090]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      2325\n",
      "           2       0.99      1.00      1.00      1090\n",
      "\n",
      "    accuracy                           1.00      3415\n",
      "   macro avg       1.00      1.00      1.00      3415\n",
      "weighted avg       1.00      1.00      1.00      3415\n",
      "\n",
      "0.9976573938506589\n"
     ]
    }
   ],
   "source": [
    "#Shows the accuracy after post tuning\n",
    "print(confusion_matrix(y_test, post_tune_NB_predict))\n",
    "print(classification_report(y_test, post_tune_NB_predict))\n",
    "print(accuracy_score(y_test, post_tune_NB_predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have the accuracy to its highest, we need to present it so that its presentable \n",
    "#We shall us matplot to present our plots\n",
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2180156a52e32991628e5a4a8b5c90bcd9295ad24454987d4793afc932ccd443"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
